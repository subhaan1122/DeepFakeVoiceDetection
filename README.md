# ğŸ™ï¸ Deepfake Voice Detection

An end-to-end AI system to detect deepfake voice recordings using both **audio features** and **transcribed text** from the audio. 
This project uses **XGBoost classifiers** trained on engineered features and **OpenAI Whisper** for transcription.

## ğŸš€ Key Features

- ğŸ§ **Extracts 43 audio features**:
  - MFCCs
  - Delta MFCCs
  - Pitch variance
  - Spectral contrast
  - Spectral flux
- ğŸ“ **Transcribes audio using OpenAI Whisper**
- ğŸ§  **Trains three XGBoost models**:
  - Audio-only
  - Text-only
  - Combined (audio + text)
- ğŸ“Š **Evaluates all models**:
  - Confusion matrix
  - ROC-AUC
  - Classification report
- ğŸ’¬ **Interpretable predictions**:
  - Custom logic explains why a sample is classified as fake or real
- ğŸŒ **Streamlit Web App**:
  - Upload `.wav` or `.mp3` files
  - Get instant predictions with reasoning
- ğŸ’¾ **Preprocessed CSVs, saved models, and visualizations** included

---

## ğŸ§  Tech Stack

- **Python 3.11**
- **Librosa** â€“ Audio feature extraction
- **OpenAI Whisper** â€“ Transcription
- **XGBoost** â€“ Classification
- **Scikit-learn** â€“ Preprocessing, evaluation
- **Streamlit** â€“ Frontend interface
- **Pandas**, **Joblib**, **TQDM**

---

## ğŸ“‚ Project Structure

ğŸ“¦ Deepfake Voice Detection
â”œâ”€â”€ data_preparation.py
â”œâ”€â”€ feature_extraction.py
â”œâ”€â”€ vectorize_features.py
â”œâ”€â”€ train_xgboost.py
â”œâ”€â”€ app.py


## ğŸ“ˆ Model Results

| Model        | Accuracy | AUC     |
|--------------|----------|---------|
| Audio-only   | ~84%     | ~0.91   |
| Text-only    | ~56%     | ~0.58   |
| Combined     | **~80%** | **0.87** |


## ğŸ” How It Works

1. **Audio Feature Extraction**  
   43 custom audio features from each `.wav`/`.mp3` file using `librosa`

2. **Text Transcription**  
   Uses OpenAI Whisper to convert speech to text

3. **Vectorization**  
   - Audio â†’ Scaled with `StandardScaler`  
   - Text â†’ Transformed via `TfidfVectorizer` (1000 features)

4. **Model Training**  
   Trains 3 models:
   - Audio-only
   - Text-only
   - Combined (audio + transcript)

5. **Prediction Logic**  
   Uses probabilities from all models to make a final prediction with custom fallback logic:

6. **Explainability**

Every prediction includes:

- ğŸ”Š Audio patterns (e.g., pitch, spectral variation)
- ğŸ“ Text traits (length, punctuation, case)
- ğŸ”€ Combined logic reasoning

7. **ğŸ”® Sample Output**

âœ… Final Prediction: Fake
ğŸ“„ Transcript: "Hi there, I'm an AI-generated voice used for testing."

ğŸ“Œ Reasoning:
- ğŸ”Š High variation in audio frequencies.
- ğŸ¤ Unusual pitch variation detected.
- ğŸ“œ Transcript is long and coherent.
- ğŸ”€ Combined analysis of audio and text features.

8. **ğŸ† Achievements**

- âœ… End-to-end audio+NLP pipeline
- âœ… Handles edge cases & borderline decisions
- âœ… Real-time usable with GUI
- âœ… Combines ML, audio signal processing, and LLM transcription

**â­ If you liked this project, consider starring the repo!**
